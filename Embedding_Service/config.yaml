# Web server settings
server:
  host: "0.0.0.0"
  port: 8000

# List of embedding models to load and serve.
# 'name' is the alias you will use in API calls.
# 'hf_model_path' is the model identifier from Hugging Face Hub.
models:
  # - name: "all-MiniLM-L6-v2"
  #   hf_model_path: "sentence-transformers/all-MiniLM-L6-v2"
  #   local_model_path: "./models_cache/all-MiniLM-L6-v2"
  #   trust_remote_code: true
  #   tensor_parallel_size: 8  # Adjust based on your number of GPUs
  #   max_model_len: 256      # Max sequence length for the model

  - name: "laion/CLIP-ViT-B-32-laion2B-s34B-b79K"
    hf_model_path: "sentence-transformers/clip-ViT-B-32"
    trust_remote_code: true
    local_model_path: "./models_cache/clip-ViT-B-32"
    tensor_parallel_size: 1  # Adjust based on your number of GPUs
    max_model_len: 77      # Max sequence length for the model

  # - name: "gte-large"
  #   hf_model_path: "thenlper/gte-large"
  #   trust_remote_code: true
  #   tensor_parallel_size: 1
  #   max_model_len: 512

#  - name: "e5-large"
#    hf_model_path: "intfloat/e5-large-v2"
#    trust_remote_code: true
#    tensor_parallel_size: 1
#    max_model_len: 512
