# ====================================================================
# 通用数据库配置 (Universal Database Configuration)
# ====================================================================
sqlite:
  # ====================================================================
  # 数据集: toy_spider
  # ====================================================================
  toy_spider:
    services: &common_services
      vllm:
        api_url: "http://127.0.0.1:8000/v1"
        model_name: "/mnt/b_public/data/ydw/model/Qwen/Qwen2.5-72B-Instruct"
      
      openai:
        api_key: &common_api_key "sk-xxxxx"
        base_url: "http://123.129.219.111:3000/v1"
        llm_model_name: "gpt-4o"
        embedding_model_name: "all-MiniLM-L6-v2"

      embed:
        api_url: "http://127.0.0.1:8001/embed"

    # ------------------------------------------------------------------
    # 路径配置 - 在这里使用锚点 (&) 定义一个可复用的代码块
    # ------------------------------------------------------------------
    paths: &common_paths # <-- (1) 使用 &common_paths 定义锚点
      generate_tables_json_path: "sqlite/train/{dataset}/tables.json"
      result_path: "sqlite/results/{dataset}"
      enhance_json_name: "enhanced_train_tables.json"
      source_db_root: "sqlite/train/{dataset}"
      sql_script_dir: "sqlite/results/{dataset}/vector_sql"
      vector_db_root: "sqlite/results/{dataset}/vector_databases"
      find_semantic_table_json: "sqlite/results/{dataset}/find_semantic_tables.json"
      find_semantic_prompt_template_path: "sqlite/prompt_templates/find_semantic_rich_column.txt"
      model_download: '/mnt/b_public/data/yaodongwen/model'
      cache_file: "sqlite/cache/{dataset}/disk_cache"
      original_schema: "sqlite/results/{dataset}/find_semantic_tables.json"
      schema_output_dir: "sqlite/results/{dataset}"
      schema_output_json: "embedding_table_vector.json"
      prompt_tpl_path: "sqlite/prompt_templates/sql_synthesis_prompt.txt"
      functions_path: "sqlite/prompt_templates/sqlite_funcs.json"
      sql_prompts_output_dir: "sqlite/prompts/{dataset}"
      sql_prompts_output_name: "sql_synthesis_prompts.json"
      synthesize_sql_input_file: "sqlite/prompts/{dataset}/sql_synthesis_prompts.json"
      synthesize_sql_output_file: "sqlite/results/{dataset}/sql_synthesis.json"
      cache_file_path_sql: "sqlite/cache/{dataset}/disk_cache/disk_cache_sql.jsonl"
      EMBED_MODEL_PATH: "../../model/all-MiniLM-L6-v2.e4ce9877.q8_0.gguf"
      EMBED_MODEL_PATH_CACHE: "cache/model"
      post_sql_output_path: "sqlite/results/{dataset}/synthetic_sqls.json"
      post_sql_llm_json_path: "sqlite/results/{dataset}/sql_synthesis.json"
      sql_infos_path: "sqlite/results/{dataset}/synthetic_sqls.json"
      question_synthesis_template_path: "sqlite/prompt_templates/question_synthesis_prompt.txt"
      question_prompts_output_json_path: "sqlite/prompts/{dataset}/question_synthesis_prompts.json"
      synthesize_question_input_file: "sqlite/prompts/{dataset}/question_synthesis_prompts.json"
      cache_file_path_question: "sqlite/cache/{dataset}/disk_cache/disk_cache_question.jsonl"
      synthesize_question_output_file: "sqlite/results/{dataset}/question_synthesis.json"
      post_process_questions_input_dataset_path: "sqlite/results/{dataset}/question_synthesis.json"
      post_process_questions_output_file: "sqlite/results/{dataset}/question_and_sql_pairs.json"
      model_name_or_path: "sentence-transformers/all-mpnet-base-v2"
      synthesiaze_candidate_input_file: "sqlite/results/{dataset}/question_and_sql_pairs.json"
      synthesiaze_candidate_output_file: "sqlite/results/{dataset}/candidate_sql.json"
      gene_cot_prompts_dataset_json_path: "sqlite/results/{dataset}/candidate_sql.json"
      gene_cot_prompts_tables_json_path: "sqlite/results/{dataset}/embedding_table_vector.json"
      gene_cot_prompts_prompt_tamplate_path: "sqlite/prompt_templates/cot_synthesis_prompt_template.txt"
      gene_cot_prompts_output_prompt_path: "sqlite/prompts/{dataset}/cot_synthesis_prompts.json"
      synthesize_cot_output_file: "sqlite/results/{dataset}/cot_synthesis.json"
      cache_file_path_cot: "sqlite/cache/{dataset}/disk_cache/disk_cache_cot"
      post_process_cot_results_path: "sqlite/results/{dataset}/cot_synthesis.json"
      post_process_cot_db_dir: "sqlite/results/{dataset}/vector_databases"
      post_process_cot_output_dir: "sqlite/results/{dataset}"
      dataset_json_path_input: "../pipeline/sqlite/results/{dataset}/candidate_sql.json"
      tables_json_path_input: "../pipeline/sqlite/results/{dataset}/embedding_table_vector.json"
      prompt_tamplate_path_infer_input: "../pipeline/sqlite/prompt_templates/sql_generate_prompt_template.txt"
      output_path_input: "../pipeline/sqlite/results/{dataset}/input_llm.json"
      database_note_prompt_path: "../pipeline/sqlite/prompt_templates/sqlite_vec_note_prompt.txt"

    parameters: &common_parameters
      dataset_backend: "sqlite"
      max_workers: 32
      no_parallel_find_semantic_rich: false
      num_cpus: 10
      sql_exec_timeout: 60
      num_candidates: 5
      sql_number: 5 #这个参数特别重要！控制最终文件的大小。
      # 它在最开始控制对每个向量列生成多少条对应的sql语句（只是在最开始，由于后续会筛选掉不合格的sql，所以最终结果的数目比这个参数值乘以语义丰富的列数要小很多）

  # ====================================================================
  # 测试: test
  # ====================================================================
  test:
    services: *common_services
    
    # ------------------------------------------------------------------
    # 直接使用别名 (*) 复用上面定义的 paths 代码块
    # ------------------------------------------------------------------
    paths: *common_paths # <-- (2) 使用 *common_paths 引用锚点

    parameters: *common_parameters

  # ====================================================================
  # 合成数据: synthesis_data
  # ====================================================================
  synthesis_data:
    services: *common_services
    
    # ------------------------------------------------------------------
    # 直接使用别名 (*) 复用上面定义的 paths 代码块
    # ------------------------------------------------------------------
    paths: 
      generate_tables_json_path: "sqlite/train/{dataset}/tables.json"
      result_path: "sqlite/results/{dataset}"
      enhance_json_name: "enhanced_train_tables.json"
      source_db_root: "sqlite/train/{dataset}"
      sql_script_dir: "sqlite/results/{dataset}/vector_sql"
      vector_db_root: "sqlite/results/{dataset}/vector_databases"
      find_semantic_table_json: "sqlite/results/{dataset}/find_semantic_tables.json"
      find_semantic_prompt_template_path: "sqlite/prompt_templates/find_semantic_rich_column.txt"
      model_download: '/mnt/b_public/data/yaodongwen/model'
      cache_file: "sqlite/cache/{dataset}/disk_cache"
      original_schema: "sqlite/results/{dataset}/find_semantic_tables.json"
      schema_output_dir: "sqlite/results/{dataset}"
      schema_output_json: "embedding_table_vector.json"
      prompt_tpl_path: "sqlite/prompt_templates/sql_synthesis_prompt.txt"
      functions_path: "sqlite/prompt_templates/sqlite_funcs.json"
      sql_prompts_output_dir: "sqlite/prompts/{dataset}"
      sql_prompts_output_name: "sql_synthesis_prompts.json"
      synthesize_sql_input_file: "sqlite/prompts/{dataset}/sql_synthesis_prompts.json"
      synthesize_sql_output_file: "sqlite/results/{dataset}/sql_synthesis.json"
      cache_file_path_sql: "sqlite/cache/{dataset}/disk_cache/disk_cache_sql.jsonl"
      EMBED_MODEL_PATH: "../../model/all-MiniLM-L6-v2.e4ce9877.q8_0.gguf"
      EMBED_MODEL_PATH_CACHE: "cache/model"
      post_sql_output_path: "sqlite/results/{dataset}/synthetic_sqls.json"
      post_sql_llm_json_path: "sqlite/results/{dataset}/sql_synthesis.json"
      sql_infos_path: "sqlite/results/{dataset}/synthetic_sqls.json"
      question_synthesis_template_path: "sqlite/prompt_templates/question_synthesis_prompt.txt"
      question_prompts_output_json_path: "sqlite/prompts/{dataset}/question_synthesis_prompts.json"
      synthesize_question_input_file: "sqlite/prompts/{dataset}/question_synthesis_prompts.json"
      cache_file_path_question: "sqlite/cache/{dataset}/disk_cache/disk_cache_question.jsonl"
      synthesize_question_output_file: "sqlite/results/{dataset}/question_synthesis.json"
      post_process_questions_input_dataset_path: "sqlite/results/{dataset}/question_synthesis.json"
      post_process_questions_output_file: "sqlite/results/{dataset}/question_and_sql_pairs.json"
      model_name_or_path: "sentence-transformers/all-mpnet-base-v2"
      synthesiaze_candidate_input_file: "sqlite/results/{dataset}/question_and_sql_pairs.json"
      synthesiaze_candidate_output_file: "sqlite/results/{dataset}/candidate_sql.json"
      gene_cot_prompts_dataset_json_path: "sqlite/results/{dataset}/candidate_sql.json"
      gene_cot_prompts_tables_json_path: "sqlite/results/{dataset}/embedding_table_vector.json"
      gene_cot_prompts_prompt_tamplate_path: "sqlite/prompt_templates/cot_synthesis_prompt_template.txt"
      gene_cot_prompts_output_prompt_path: "sqlite/prompts/{dataset}/cot_synthesis_prompts.json"
      synthesize_cot_output_file: "sqlite/results/{dataset}/cot_synthesis.json"
      cache_file_path_cot: "sqlite/cache/{dataset}/disk_cache/disk_cache_cot"
      post_process_cot_results_path: "sqlite/results/{dataset}/cot_synthesis.json"
      post_process_cot_db_dir: "sqlite/results/{dataset}/vector_databases"
      post_process_cot_output_dir: "sqlite/results/{dataset}"
      dataset_json_path_input: "../pipeline/sqlite/results/{dataset}/synthetic_text2sql_dataset.json"
      tables_json_path_input: "../pipeline/sqlite/results/{dataset}/embedding_table_vector.json"
      prompt_tamplate_path_infer_input: "../pipeline/sqlite/prompt_templates/sql_generate_prompt_template.txt"
      output_path_input: "../pipeline/sqlite/results/{dataset}/input_llm.json"
      database_note_prompt_path: "../pipeline/sqlite/prompt_templates/sqlite_vec_note_prompt.txt"
      # output_llm_train_path: "../pipeline/sqlite/results/{dataset}/output_llm.json"

    parameters:
      dataset_backend: "sqlite"
      max_workers: 64
      no_parallel_find_semantic_rich: false
      num_cpus: 10
      sql_exec_timeout: 60
      num_candidates: 5
      sql_number: 2 #这个参数特别重要！控制最终文件的大小。
      # 它在最开始控制对每个向量列生成多少条对应的sql语句（只是在最开始，由于后续会筛选掉不合格的sql，所以最终结果的数目比这个参数值乘以语义丰富的列数要小很多）

  # ====================================================================
  # 数据集: bird
  # ====================================================================
  bird:
    # services 和 parameters 可以是 bird 数据集特有的
    services: *common_services
    
    # ------------------------------------------------------------------
    # 直接使用别名 (*) 复用上面定义的 paths 代码块
    # ------------------------------------------------------------------
    paths: *common_paths # <-- (2) 使用 *common_paths 引用锚点

    parameters: *common_parameters

  # ====================================================================
  # 数据集: arxiv
  # ====================================================================
  arxiv:
    # services 和 parameters 可以是 bird 数据集特有的
    services: *common_services
    
    # ------------------------------------------------------------------
    # 直接使用别名 (*) 复用上面定义的 paths 代码块
    # ------------------------------------------------------------------
    paths: *common_paths # <-- (2) 使用 *common_paths 引用锚点

    parameters:
      dataset_backend: "sqlite"
      max_workers: 32
      no_parallel_find_semantic_rich: false
      num_cpus: 10
      sql_exec_timeout: 60
      num_candidates: 5
      sql_number: 75 # this number is vary big, because the semantically rich column number of this dataset is vary small

  # ====================================================================
  # 数据集: spider
  # ====================================================================
  spider:
    # services 和 parameters 可以是 bird 数据集特有的
    services: *common_services
    
    # ------------------------------------------------------------------
    # 直接使用别名 (*) 复用上面定义的 paths 代码块
    # ------------------------------------------------------------------
    paths: *common_paths # <-- (2) 使用 *common_paths 引用锚点

    parameters: 
      dataset_backend: "sqlite"
      max_workers: 32
      no_parallel_find_semantic_rich: false
      num_cpus: 10
      sql_exec_timeout: 60
      num_candidates: 5
      sql_number: 1 #这个参数特别重要！控制最终文件的大小。

  # ====================================================================
  # 数据集: wikipedia_multimodal
  # ====================================================================
  wikipedia_multimodal:
    # services 和 parameters 可以是 bird 数据集特有的
    services:
      vllm:
        api_url: "http://127.0.0.1:8000/v1"
        model_name: "/mnt/b_public/data/ydw/model/Qwen/Qwen2.5-72B-Instruct"
      
      openai:
        api_key: *common_api_key
        base_url: "http://123.129.219.111:3000/v1"
        llm_model_name: "gpt-4o"
        embedding_model_name: "laion/CLIP-ViT-B-32-laion2B-s34B-b79K"
    
    paths: 
      generate_tables_json_path: "sqlite/train/{dataset}/tables.json"
      result_path: "sqlite/results/{dataset}"
      enhance_json_name: "enhanced_train_tables.json"
      source_db_root: "sqlite/train/{dataset}"
      sql_script_dir: "sqlite/results/{dataset}/vector_sql"
      vector_db_root: "sqlite/results/{dataset}/vector_databases"
      find_semantic_table_json: "sqlite/results/{dataset}/find_semantic_tables.json"
      find_semantic_prompt_template_path: "sqlite/prompt_templates/find_semantic_rich_column.txt"
      cache_file_path_sql: "sqlite/cache/{dataset}/disk_cache/disk_cache_sql.jsonl"
      EMBED_MODEL_PATH_CACHE: "cache/model"
      model_download: '/mnt/b_public/data/yaodongwen/model'
      cache_file: "sqlite/cache/{dataset}/disk_cache"
      original_schema: "sqlite/results/{dataset}/find_semantic_tables.json"
      schema_output_dir: "sqlite/results/{dataset}"

      # image_embedding_adder.py
      intermediate_sql_path: "sqlite/results/{dataset}/vector_sql/{dataset}_vector.sql"
      target_vec_db_path: "sqlite/results/{dataset}/vector_databases/{dataset}/{dataset}.sqlite"
      final_image_vec_db_path: "sqlite/results/{dataset}/vector_databases/{dataset}/{dataset}_final.sqlite"
      table_to_modify: 'Images'
      model_cache_directory: 'cache/model'
      article_table: "Articles"
      image_root_directory: 'sqlite/train/{dataset}'

      schema_output_json: "embedding_table_vector.json"
      prompt_tpl_path: "sqlite/prompt_templates/sql_synthesis_prompt.txt"
      functions_path: "sqlite/prompt_templates/sqlite_funcs.json"
      sql_prompts_output_dir: "sqlite/prompts/{dataset}"
      sql_prompts_output_name: "sql_synthesis_prompts.json"
      synthesize_sql_input_file: "sqlite/prompts/{dataset}/sql_synthesis_prompts.json"
      synthesize_sql_output_file: "sqlite/results/{dataset}/sql_synthesis.json"
      EMBED_MODEL_PATH: "../../model/all-MiniLM-L6-v2.e4ce9877.q8_0.gguf"
      post_sql_output_path: "sqlite/results/{dataset}/synthetic_sqls.json"
      post_sql_llm_json_path: "sqlite/results/{dataset}/sql_synthesis.json"
      sql_infos_path: "sqlite/results/{dataset}/synthetic_sqls.json"
      question_synthesis_template_path: "sqlite/prompt_templates/question_synthesis_prompt.txt"
      question_prompts_output_json_path: "sqlite/prompts/{dataset}/question_synthesis_prompts.json"
      synthesize_question_input_file: "sqlite/prompts/{dataset}/question_synthesis_prompts.json"
      cache_file_path_question: "sqlite/cache/{dataset}/disk_cache/disk_cache_question.jsonl"
      synthesize_question_output_file: "sqlite/results/{dataset}/question_synthesis.json"
      post_process_questions_input_dataset_path: "sqlite/results/{dataset}/question_synthesis.json"
      post_process_questions_output_file: "sqlite/results/{dataset}/question_and_sql_pairs.json"
      model_name_or_path: "laion/CLIP-ViT-B-32-laion2B-s34B-b79K"
      synthesiaze_candidate_input_file: "sqlite/results/{dataset}/question_and_sql_pairs.json"
      synthesiaze_candidate_output_file: "sqlite/results/{dataset}/candidate_sql.json"
      gene_cot_prompts_dataset_json_path: "sqlite/results/{dataset}/candidate_sql.json"
      gene_cot_prompts_tables_json_path: "sqlite/results/{dataset}/embedding_table_vector.json"
      gene_cot_prompts_prompt_tamplate_path: "sqlite/prompt_templates/cot_synthesis_prompt_template.txt"
      gene_cot_prompts_output_prompt_path: "sqlite/prompts/{dataset}/cot_synthesis_prompts.json"
      synthesize_cot_output_file: "sqlite/results/{dataset}/cot_synthesis.json"
      cache_file_path_cot: "sqlite/cache/{dataset}/disk_cache_cot"
      post_process_cot_results_path: "sqlite/results/{dataset}/cot_synthesis.json"
      post_process_cot_db_dir: "sqlite/results/{dataset}/vector_databases"
      post_process_cot_output_dir: "sqlite/results/{dataset}"   
      dataset_json_path_input: "../pipeline/sqlite/results/{dataset}/candidate_sql.json"
      tables_json_path_input: "../pipeline/sqlite/results/{dataset}/embedding_table_vector.json"
      prompt_tamplate_path_infer_input: "../pipeline/sqlite/prompt_templates/sql_generate_prompt_template.txt"
      output_path_input: "../pipeline/sqlite/results/{dataset}/input_llm.json"
      database_note_prompt_path: "../pipeline/sqlite/prompt_templates/sqlite_vec_note_prompt.txt"

    parameters:
      dataset_backend: "sqlite"
      max_workers: 32
      no_parallel_find_semantic_rich: false
      num_cpus: 10
      sql_exec_timeout: 60
      num_candidates: 5
      sql_number: 70 #这个参数特别重要！控制最终文件的大小。
