import os
import json
import sqlite3
import argparse
from tqdm import tqdm

def get_schema_for_db(db_path):
    """
    è¿æ¥åˆ°å•ä¸ª SQLite æ•°æ®åº“ï¼Œæ£€æŸ¥å…¶ schemaï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸ã€‚

    Args:
        db_path (str): æ•°æ®åº“æ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        dict: åŒ…å«æ•°æ®åº“ schema ä¿¡æ¯çš„å­—å…¸ï¼Œå¦‚æœå‡ºé”™åˆ™è¿”å› Noneã€‚
    """
    try:
        # ä»æ–‡ä»¶è·¯å¾„ä¸­æå– db_id
        # ä¿®æ­£ï¼šdb_id åº”è¯¥æ˜¯æ•°æ®åº“æ‰€åœ¨çš„æ–‡ä»¶å¤¹åï¼Œä¸ Spider æ•°æ®é›†æ ¼å¼ä¿æŒä¸€è‡´
        db_id = os.path.basename(os.path.dirname(db_path))
        
        # åˆå§‹åŒ– schema å­—å…¸ç»“æ„
        schema = {
            "db_id": db_id,
            "table_names_original": [],
            "table_names": [],
            "column_names_original": [[-1, "*"]], # åŒ…å«é€šé…ç¬¦ '*'
            "column_names": [[-1, "*"]],
            "column_types": ["text"],
            "primary_keys": [],
            "foreign_keys": []
        }

        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 1. è·å–æ‰€æœ‰è¡¨å
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';")
        table_names = [row[0] for row in cursor.fetchall()]
        schema["table_names_original"] = table_names
        schema["table_names"] = table_names
        
        # ç”¨äºå¿«é€ŸæŸ¥æ‰¾è¡¨åå¯¹åº”çš„ç´¢å¼•
        table_name_to_idx = {name: i for i, name in enumerate(table_names)}
        
        # ç”¨äºåç»­æŸ¥æ‰¾å¤–é”®æ—¶ï¼Œå¿«é€Ÿå®šä½åˆ—çš„å…¨å±€ç´¢å¼•
        column_to_global_idx = {}
        current_col_idx = 1 # ä» 1 å¼€å§‹ï¼Œå› ä¸º 0 è¢« '*' å ç”¨

        # 2. éå†æ¯ä¸ªè¡¨ï¼Œè·å–åˆ—ä¿¡æ¯å’Œä¸»é”®
        for table_idx, table_name in enumerate(table_names):
            cursor.execute(f'PRAGMA table_info("{table_name}");')
            columns_info = cursor.fetchall()

            for col in columns_info:
                # col æ ¼å¼: (cid, name, type, notnull, dflt_value, pk)
                col_name = col[1]
                col_type = col[2].upper() # ä¿æŒä¸ Spider æ•°æ®é›†ä¸€è‡´ï¼Œé€šå¸¸ä¸ºå¤§å†™
                is_primary_key = col[5] == 1

                # æ·»åŠ åˆ—ä¿¡æ¯
                schema["column_names_original"].append([table_idx, col_name])
                schema["column_names"].append([table_idx, col_name])
                schema["column_types"].append(col_type)

                # è®°å½•ä¸»é”®
                if is_primary_key:
                    schema["primary_keys"].append(current_col_idx)
                
                # å»ºç«‹ (è¡¨å, åˆ—å) -> å…¨å±€ç´¢å¼• çš„æ˜ å°„
                column_to_global_idx[(table_name, col_name)] = current_col_idx
                current_col_idx += 1

        # 3. éå†æ¯ä¸ªè¡¨ï¼Œè·å–å¤–é”®ä¿¡æ¯
        for table_idx, table_name in enumerate(table_names):
            cursor.execute(f'PRAGMA foreign_key_list("{table_name}");')
            foreign_keys_info = cursor.fetchall()

            for fk in foreign_keys_info:
                # fk æ ¼å¼: (id, seq, table, from, to, on_update, on_delete, match)
                from_column = fk[3]
                to_table = fk[2]
                to_column = fk[4]

                # æŸ¥æ‰¾æºåˆ—å’Œç›®æ ‡åˆ—çš„å…¨å±€ç´¢å¼•
                from_col_idx = column_to_global_idx.get((table_name, from_column))
                to_col_idx = column_to_global_idx.get((to_table, to_column))

                if from_col_idx is not None and to_col_idx is not None:
                    schema["foreign_keys"].append([from_col_idx, to_col_idx])

        conn.close()
        return schema

    except sqlite3.Error as e:
        # ä½¿ç”¨ os.path.basename(db_path) ä½¿å¾—é”™è¯¯ä¿¡æ¯æ›´æ¸…æ™°
        print(f"  [é”™è¯¯] å¤„ç†æ•°æ®åº“ {os.path.basename(db_path)} å¤±è´¥: {e}")
        return None


def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºè§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œå¹¶ä¸ºæŒ‡å®šç›®å½•ä¸­çš„æ‰€æœ‰æ•°æ®åº“ç”Ÿæˆ schemaã€‚
    """
    parser = argparse.ArgumentParser(description="ä¸ºç›®å½•ä¸­çš„ SQLite æ•°æ®åº“ç”Ÿæˆ Schema JSON æ–‡ä»¶ã€‚")
    parser.add_argument(
        "--db-dir", 
        required=True, 
        help="åŒ…å« .sqlite æˆ– .db æ•°æ®åº“æ–‡ä»¶çš„æ ¹ç›®å½•è·¯å¾„ã€‚"
    )
    parser.add_argument(
        "--output-file", 
        required=True, 
        help="ç”Ÿæˆçš„ schema JSON æ–‡ä»¶çš„è¾“å‡ºè·¯å¾„ã€‚"
    )
    args = parser.parse_args()

    if not os.path.isdir(args.db_dir):
        print(f"âœ– é”™è¯¯ï¼šç›®å½• '{args.db_dir}' ä¸å­˜åœ¨ã€‚")
        return

    print(f"ğŸš€ å¼€å§‹ä»ç›®å½• '{args.db_dir}' åŠå…¶å­ç›®å½•ä¸­é€’å½’æŸ¥æ‰¾æ•°æ®åº“...")

    # --- ä¸»è¦ä¿®æ”¹éƒ¨åˆ† ---
    # ä½¿ç”¨ os.walk() é€’å½’éå†ç›®å½•ä»¥æŸ¥æ‰¾æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶
    db_files = []
    for root, dirs, files in os.walk(args.db_dir):
        for file in files:
            if file.endswith(('.sqlite', '.db')):
                db_files.append(os.path.join(root, file))
    # --- ä¿®æ”¹ç»“æŸ ---

    if not db_files:
        print("ğŸŸ¡ è­¦å‘Šï¼šåœ¨æŒ‡å®šç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•ä¸­å‡æœªæ‰¾åˆ° .sqlite æˆ– .db æ–‡ä»¶ã€‚")
        return
    
    # æŒ‰ç…§å­—æ¯é¡ºåºå¤„ç†ï¼Œä¿è¯è¾“å‡ºç»“æœçš„ç¨³å®šæ€§
    db_files.sort()

    all_schemas = []
    for db_path in tqdm(db_files, desc="å¤„ç†æ•°æ®åº“ä¸­"):
        schema_data = get_schema_for_db(db_path)
        if schema_data:
            all_schemas.append(schema_data)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(args.output_file)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        
    try:
        with open(args.output_file, 'w', encoding='utf-8') as f:
            json.dump(all_schemas, f, indent=4, ensure_ascii=False) # indent=4 æ ¼å¼æ›´ç¾è§‚
        print(f"\nâœ” æˆåŠŸåˆ›å»º schema æ–‡ä»¶ '{args.output_file}'ï¼ŒåŒ…å« {len(all_schemas)} ä¸ªæ•°æ®åº“ã€‚")
    except IOError as e:
        print(f"\nâœ– å†™å…¥è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")


if __name__ == '__main__':
    main()
